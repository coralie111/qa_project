{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ColumnTransformer] . (1 of 7) Processing passthrough-1, total=   0.0s\n",
      "[Pipeline] .. (step 1 of 5) Processing patternremover-1, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 5) Processing patternremover-2, total=   0.1s\n",
      "[Pipeline] .. (step 3 of 5) Processing patternremover-3, total=   0.2s\n",
      "[Pipeline] .. (step 4 of 5) Processing patternremover-4, total=   0.0s\n",
      "[Pipeline] . (step 5 of 5) Processing spellingcorrecter, total=   0.2s\n",
      "[ColumnTransformer] .... (2 of 7) Processing pipeline-1, total=   0.5s\n",
      "[Pipeline] .. (step 1 of 5) Processing patternremover-1, total=   0.1s\n",
      "[Pipeline] .. (step 2 of 5) Processing patternremover-2, total=   0.1s\n",
      "[Pipeline] .. (step 3 of 5) Processing patternremover-3, total=   0.2s\n",
      "[Pipeline] .. (step 4 of 5) Processing patternremover-4, total=   0.0s\n",
      "[Pipeline] . (step 5 of 5) Processing spellingcorrecter, total=   0.2s\n",
      "[ColumnTransformer] .... (3 of 7) Processing pipeline-2, total=   0.6s\n",
      "[ColumnTransformer] . (4 of 7) Processing passthrough-2, total=   0.0s\n",
      "[FeatureUnion]  (step 1 of 4) Processing patterncounter, total=   0.1s\n",
      "[FeatureUnion]  (step 2 of 4) Processing patternencoder-1, total=   0.0s\n",
      "[FeatureUnion]  (step 3 of 4) Processing patternencoder-2, total=   0.0s\n",
      "[FeatureUnion]  (step 4 of 4) Processing patternencoder-3, total=   0.0s\n",
      "[ColumnTransformer]  (5 of 7) Processing featureunion-1, total=   0.1s\n",
      "[FeatureUnion]  (step 1 of 2) Processing patterncounter, total=   0.0s\n",
      "[FeatureUnion]  (step 1 of 4) Processing patterncounter, total=   0.6s\n",
      "[FeatureUnion]  (step 2 of 4) Processing patternencoder-1, total=   0.1s\n",
      "[FeatureUnion]  (step 3 of 4) Processing patternencoder-2, total=   0.0s\n",
      "[FeatureUnion]  (step 4 of 4) Processing patternencoder-3, total=   0.1s\n",
      "[FeatureUnion] .. (step 2 of 2) Processing featureunion, total=   0.9s\n",
      "[ColumnTransformer]  (6 of 7) Processing featureunion-2, total=   0.9s\n",
      "[FeatureUnion]  (step 1 of 2) Processing patterncounter, total=   0.0s\n",
      "[FeatureUnion]  (step 1 of 4) Processing patterncounter, total=   0.6s\n",
      "[FeatureUnion]  (step 2 of 4) Processing patternencoder-1, total=   0.1s\n",
      "[FeatureUnion]  (step 3 of 4) Processing patternencoder-2, total=   0.0s\n",
      "[FeatureUnion]  (step 4 of 4) Processing patternencoder-3, total=   0.1s\n",
      "[FeatureUnion] .. (step 2 of 2) Processing featureunion, total=   0.9s\n",
      "[ColumnTransformer]  (7 of 7) Processing featureunion-3, total=   0.9s\n",
      "[Pipeline] .......... (step 1 of 3) Processing squeezer, total=   0.0s\n",
      "[Pipeline]  (step 2 of 3) Processing lemmatfidfvectorizer, total=   1.6s\n",
      "[Pipeline] ...... (step 3 of 3) Processing truncatedsvd, total=   0.0s\n",
      "[ColumnTransformer] .... (1 of 5) Processing pipeline-1, total=   1.6s\n",
      "[Pipeline] .......... (step 1 of 3) Processing squeezer, total=   0.0s\n",
      "[Pipeline]  (step 2 of 3) Processing lemmatfidfvectorizer, total=   2.9s\n",
      "[Pipeline] ...... (step 3 of 3) Processing truncatedsvd, total=   0.3s\n",
      "[ColumnTransformer] .... (2 of 5) Processing pipeline-2, total=   3.2s\n",
      "[Pipeline] .......... (step 1 of 3) Processing squeezer, total=   0.0s\n",
      "[Pipeline]  (step 2 of 3) Processing lemmatfidfvectorizer, total=   3.7s\n",
      "[Pipeline] ...... (step 3 of 3) Processing truncatedsvd, total=   0.3s\n",
      "[ColumnTransformer] .... (3 of 5) Processing pipeline-3, total=   4.0s\n",
      "[ColumnTransformer] . (4 of 5) Processing onehotencoder, total=   0.0s\n",
      "[ColumnTransformer] ..... (5 of 5) Processing remainder, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import re\n",
    "import joblib\n",
    "import sklearn.feature_extraction.text as txt\n",
    "\n",
    "from paths import joblib_dir\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "import classification_lib as cl\n",
    "import cosine_normalisation_pipeline as cnp\n",
    "import stop_words_perso as swp \n",
    "import mispell_dict as md\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "y = train.iloc[:, 11:]\n",
    "\n",
    "# transformation des targets variables catégorielles\n",
    "#y_transformed = y.apply(lambda x: pd.cut(x,\n",
    "#                        [-0.1, .25, .5, .75, 1.1],\n",
    "#                        labels=['low', 'medium-', 'medium+', 'high']))\n",
    "y_transformed = y\n",
    "\n",
    "# séparation en cas d'études séparés sur les questions ou answers\n",
    "y_question = y_transformed.loc[:, y_transformed.columns.str.startswith('question')]\n",
    "y_answer = y_transformed.loc[:, y_transformed.columns.str.startswith('answer')]\n",
    "\n",
    "to_delete_var = ['qa_id', 'url',\n",
    "                 'question_user_name', 'question_user_page',\n",
    "                 'answer_user_name', 'answer_user_page']\n",
    "\n",
    "X = train.iloc[:, :11].drop(to_delete_var, 1)\n",
    "X_title = train.question_title\n",
    "X_question = train.question_body\n",
    "X_answer = train.answer\n",
    "\n",
    "# nombre de lignes avec passage à la ligne comme proxy\n",
    "linebreak_re = r'\\n'\n",
    "# longueur/verbosité avec nombre de caractères comme proxy\n",
    "chars_re = r'.'\n",
    "\n",
    "numbers_re = r'\\d\\.?\\d*'\n",
    "links_re = r'www[^\\s]*(?=\\s)|http[^\\s]*(?=\\s)'\n",
    "demonstrations_re = r'(?<=\\n).*[&\\^=\\+\\_\\[\\]\\{\\}\\|]+.*(?=\\n)'\n",
    "belonging_re = r'\\'s'\n",
    "# TODO: densité de ponctuation ?\n",
    "# question_mark = r'\\?'\n",
    "\n",
    "\n",
    "count_encoder_union = make_union(\n",
    "    cl.PatternCounter(chars_re),\n",
    "    cl.PatternEncoder(numbers_re),\n",
    "    cl.PatternEncoder(links_re),\n",
    "    cl.PatternEncoder(demonstrations_re),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "full_count_encoder_union = make_union(\n",
    "    cl.PatternCounter(linebreak_re),\n",
    "    count_encoder_union,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "cleaner_pipeline = make_pipeline(\n",
    "    cl.PatternRemover(numbers_re),\n",
    "    cl.PatternRemover(links_re),\n",
    "    cl.PatternRemover(demonstrations_re),\n",
    "    cl.PatternRemover(belonging_re),\n",
    "    cl.SpellingCorrecter(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "cleaner_count_encoder_ct = make_column_transformer(\n",
    "    ('passthrough', ['question_title']),\n",
    "    (cleaner_pipeline, ['question_body']),\n",
    "    (cleaner_pipeline, ['answer']),\n",
    "    ('passthrough', ['category', 'host']),\n",
    "    (count_encoder_union, ['question_title']),\n",
    "    (full_count_encoder_union, ['question_body']),\n",
    "    (full_count_encoder_union, ['answer']),\n",
    "    remainder='drop',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "X_transformed = pd.DataFrame(\n",
    "    data=cleaner_count_encoder_ct.fit_transform(train),\n",
    "    columns=[\n",
    "        'question_title', 'question_body', 'answer',\n",
    "        'category', 'host',\n",
    "        'title_chars',  'title_num', 'title_links', 'title_demo',\n",
    "        'question_linebreak', 'question_chars', 'question_num', \n",
    "        'question_links', 'question_demo',\n",
    "        'answer_linebreak', 'answer_chars', 'answer_num', \n",
    "        'answer_links', 'answer_demo'\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_transformed,\n",
    "    y_transformed,\n",
    "    test_size=0.15\n",
    ")\n",
    "\n",
    "stop_words = list(txt.ENGLISH_STOP_WORDS)\n",
    "for words in swp.stop_words_to_remove:\n",
    "    stop_words.remove(words)\n",
    "stop_words += swp.cs_stop_words \\\n",
    "              + swp.generated_during_tokenizing\n",
    "\n",
    "title_tfidftransformer = cl.LemmaTfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    stop_words=stop_words,\n",
    "    min_df=0.015,\n",
    "    max_df=0.85,\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "question_tfidftransformer = cl.LemmaTfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    stop_words=stop_words,\n",
    "    min_df=0.015,\n",
    "    max_df=0.85,\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "answer_tfidftransformer = cl.LemmaTfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    stop_words=stop_words,\n",
    "    min_df=0.015,\n",
    "    max_df=0.85,\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "title_tfidf_acp_pipe = make_pipeline(\n",
    "    cl.Squeezer(),\n",
    "    title_tfidftransformer,\n",
    "    TruncatedSVD(n_components=15),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "question_tfidf_acp_pipe = make_pipeline(\n",
    "    cl.Squeezer(),\n",
    "    question_tfidftransformer,\n",
    "    TruncatedSVD(n_components=220),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "answer_tfidf_acp_pipe = make_pipeline(\n",
    "    cl.Squeezer(),\n",
    "    answer_tfidftransformer,\n",
    "    TruncatedSVD(n_components=250),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "cat_host_ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "\n",
    "tfidf_ohe_ct = make_column_transformer(\n",
    "    (title_tfidf_acp_pipe, 0),\n",
    "    (question_tfidf_acp_pipe, 1),\n",
    "    (answer_tfidf_acp_pipe, 2),\n",
    "    (cat_host_ohe, [3,4]),\n",
    "    verbose=True,\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_train_transformed = tfidf_ohe_ct.fit_transform(X_train).astype(float)\n",
    "\n",
    "cosine_tfidftransformer = cl.LemmaTfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "cosine_tfidftransformer.fit(\n",
    "    X_train.question_title\n",
    "    + ' ' + X_train.question_body\n",
    "    + ' ' + X_train.answer\n",
    ")\n",
    "\n",
    "norm_transformer = StandardScaler().fit(X_train_transformed)\n",
    "\n",
    "X_train_transformed = cnp.do_and_stack_cosine(\n",
    "    cosine_tfidftransformer,\n",
    "    X_train_transformed,\n",
    "    X_train\n",
    "#    norm_transformer, \n",
    "#    norm=True\n",
    ")\n",
    "\n",
    "# for test usage:\n",
    "X_test_transformed = cnp.do_and_stack_cosine(\n",
    "    cosine_tfidftransformer,\n",
    "    tfidf_ohe_ct.transform(X_test),\n",
    "    X_test\n",
    "#    norm_transformer, \n",
    "#    norm=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_transformer = StandardScaler().fit(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = norm_transformer.transform(X_train_transformed)\n",
    "X_test_transformed = norm_transformer.transform(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_transformed\n",
    "X_test = X_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "\n",
    "for col in list(y_transformed.columns):\n",
    "    for item in y_transformed[col].unique():\n",
    "        l.append(item)\n",
    "set(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Multiple models\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import RegressorChain\n",
    "\n",
    "clf_rfr = RandomForestRegressor(random_state=0)\n",
    "\n",
    "param_grid_rfr = [{'n_estimators': [10, 50, 100],\n",
    "                   'min_samples_leaf': [1, 3, 5],\n",
    "                   'max_features': ['sqrt', 'log2']}]\n",
    "\n",
    "\n",
    "clf_chain = RegressorChain(RandomForestRegressor(random_state=0), order=None, cv=None, random_state=0)\n",
    "\n",
    "param_grid_chain = [{'base_estimator__n_estimators': [10, 50, 100],\n",
    "                   'base_estimator__min_samples_leaf': [1, 3, 5],\n",
    "                   'base_estimator__max_features': ['sqrt', 'log2']}]\n",
    "\n",
    "gridcvs={}\n",
    "\n",
    "for pgrid, clf, name in zip((param_grid_rfr,\n",
    "                             param_grid_chain),\n",
    "                            (clf_rfr, \n",
    "                             clf_chain),\n",
    "                            ('RFR', 'chained_RFR')):\n",
    "    gcv = GridSearchCV(clf,\n",
    "                       pgrid,\n",
    "                       cv=3,\n",
    "                       refit=True)\n",
    "    gridcvs[name] = gcv\n",
    "\n",
    "\n",
    "outer_cv = KFold(n_splits=3, shuffle=True)\n",
    "outer_scores = {}\n",
    "\n",
    "for name, gs in gridcvs.items():\n",
    "    nested_score = cross_val_score(gs, \n",
    "                                   X_train, \n",
    "                                   y_train, cv=outer_cv)\n",
    "    outer_scores[name] = nested_score\n",
    "    \n",
    "outer_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = gridcvs['chained_RFR']\n",
    "chain.fit(X_train, y_train)\n",
    "\n",
    "chain.best_params_\n",
    "\n",
    "rfr = gridcvs['RFR']\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test one model \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.multioutput import RegressorChain\n",
    "\n",
    "clf_rfr = RandomForestRegressor(random_state=0)\n",
    "\n",
    "param_grid_rfr = [{'n_estimators': [10, 50, 100],\n",
    "                   'min_samples_leaf': [1, 3, 5],\n",
    "                   'max_features': ['sqrt', 'log2']}]\n",
    "\n",
    "\n",
    "clf_chain = RegressorChain(RandomForestRegressor(random_state=0), \n",
    "                           order=[16,26,18,28,1,11,7,20,10,8,15,6,5,2,22,14,0,4,12,17,3,27,25,29,13,23,21,24,19,9],\n",
    "                           cv=None, \n",
    "                           random_state=0)\n",
    "\n",
    "param_grid_chain = [{'base_estimator__n_estimators': [100],\n",
    "                   'base_estimator__min_samples_leaf': [1, 3],\n",
    "                   'base_estimator__max_features': ['sqrt']}]\n",
    "\n",
    "\n",
    "gcv = GridSearchCV(clf_chain,param_grid_chain,cv=3, refit=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coraliebochart/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "/Users/coraliebochart/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "/Users/coraliebochart/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "/Users/coraliebochart/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "/Users/coraliebochart/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "/Users/coraliebochart/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "gcv.fit(X_train, y_train)\n",
    "y_pred = gcv.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__max_features': 'sqrt',\n",
       " 'base_estimator__min_samples_leaf': 1,\n",
       " 'base_estimator__n_estimators': 100}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([16, 26,  1, 28, 18, 11,  7, 10, 20, 22, 15,  6,  8, 14,  5,  2,  0,\n",
       "             4, 12, 25, 17,  3, 21, 27, 24, 13, 19, 29, 23,  9],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from scipy import stats\n",
    "\n",
    "y_pred = gcv.predict(X_test)\n",
    "corrs=[]\n",
    "for col in range(len(y_test.columns)):\n",
    "    corr = stats.spearmanr(pd.DataFrame(y_pred).iloc[:,col], y_test.iloc[:,col])\n",
    "    corrs.append(corr.correlation)\n",
    "\n",
    "mean_spearman = np.mean(corrs)\n",
    "\n",
    "mean_spearman\n",
    "pd.DataFrame({'target':list(y_test.columns), 'score':corrs}).sort_values(by='score', ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29922502188829403"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mean_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1509</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5945</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>932</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4706</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3157</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>912 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_asker_intent_understanding  question_body_critical  \\\n",
       "187                              1.000000                0.444444   \n",
       "1509                             0.888889                0.666667   \n",
       "1954                             1.000000                0.666667   \n",
       "370                              1.000000                0.333333   \n",
       "5945                             0.888889                0.777778   \n",
       "...                                   ...                     ...   \n",
       "932                              0.777778                0.555556   \n",
       "4561                             1.000000                0.333333   \n",
       "4706                             0.666667                0.666667   \n",
       "5791                             1.000000                0.777778   \n",
       "3157                             0.888889                0.555556   \n",
       "\n",
       "      question_conversational  question_expect_short_answer  \\\n",
       "187                       0.0                      1.000000   \n",
       "1509                      0.0                      0.666667   \n",
       "1954                      0.0                      0.666667   \n",
       "370                       0.0                      0.500000   \n",
       "5945                      0.0                      0.666667   \n",
       "...                       ...                           ...   \n",
       "932                       0.0                      0.333333   \n",
       "4561                      0.0                      0.666667   \n",
       "4706                      0.0                      1.000000   \n",
       "5791                      0.0                      0.666667   \n",
       "3157                      0.0                      0.000000   \n",
       "\n",
       "      question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "187                1.000000                                    1.0   \n",
       "1509               0.666667                                    1.0   \n",
       "1954               0.666667                                    1.0   \n",
       "370                1.000000                                    1.0   \n",
       "5945               1.000000                                    1.0   \n",
       "...                     ...                                    ...   \n",
       "932                1.000000                                    1.0   \n",
       "4561               1.000000                                    1.0   \n",
       "4706               1.000000                                    1.0   \n",
       "5791               1.000000                                    1.0   \n",
       "3157               0.000000                                    0.0   \n",
       "\n",
       "      question_interestingness_others  question_interestingness_self  \\\n",
       "187                          0.666667                       0.666667   \n",
       "1509                         0.444444                       0.333333   \n",
       "1954                         0.555556                       0.444444   \n",
       "370                          0.500000                       0.333333   \n",
       "5945                         0.444444                       0.333333   \n",
       "...                               ...                            ...   \n",
       "932                          0.666667                       0.444444   \n",
       "4561                         0.444444                       0.333333   \n",
       "4706                         0.666667                       0.333333   \n",
       "5791                         0.777778                       0.666667   \n",
       "3157                         0.666667                       0.666667   \n",
       "\n",
       "      question_multi_intent  question_not_really_a_question  ...  \\\n",
       "187                0.666667                             0.0  ...   \n",
       "1509               0.333333                             0.0  ...   \n",
       "1954               0.333333                             0.0  ...   \n",
       "370                0.000000                             0.0  ...   \n",
       "5945               0.000000                             0.0  ...   \n",
       "...                     ...                             ...  ...   \n",
       "932                0.333333                             0.0  ...   \n",
       "4561               0.000000                             0.0  ...   \n",
       "4706               0.000000                             0.0  ...   \n",
       "5791               0.000000                             0.0  ...   \n",
       "3157               0.333333                             0.0  ...   \n",
       "\n",
       "      question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "187                0.666667        1.000000                     0.555556   \n",
       "1509               0.444444        1.000000                     0.666667   \n",
       "1954               0.888889        1.000000                     0.666667   \n",
       "370                0.833333        1.000000                     0.666667   \n",
       "5945               0.777778        1.000000                     0.666667   \n",
       "...                     ...             ...                          ...   \n",
       "932                0.666667        0.666667                     0.333333   \n",
       "4561               0.888889        0.888889                     0.555556   \n",
       "4706               1.000000        0.666667                     0.333333   \n",
       "5791               0.777778        0.777778                     0.666667   \n",
       "3157               0.888889        0.777778                     0.555556   \n",
       "\n",
       "      answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "187           1.000000          1.000000             0.866667   \n",
       "1509          1.000000          1.000000             0.933333   \n",
       "1954          1.000000          1.000000             0.933333   \n",
       "370           1.000000          1.000000             0.800000   \n",
       "5945          1.000000          0.888889             0.933333   \n",
       "...                ...               ...                  ...   \n",
       "932           1.000000          0.666667             0.400000   \n",
       "4561          1.000000          0.888889             0.733333   \n",
       "4706          0.666667          0.666667             0.600000   \n",
       "5791          0.888889          0.888889             0.800000   \n",
       "3157          1.000000          1.000000             0.800000   \n",
       "\n",
       "      answer_type_instructions  answer_type_procedure  \\\n",
       "187                   0.666667               0.333333   \n",
       "1509                  1.000000               0.000000   \n",
       "1954                  0.666667               0.000000   \n",
       "370                   1.000000               0.500000   \n",
       "5945                  0.666667               0.000000   \n",
       "...                        ...                    ...   \n",
       "932                   1.000000               0.000000   \n",
       "4561                  0.000000               0.000000   \n",
       "4706                  0.000000               0.000000   \n",
       "5791                  0.666667               0.333333   \n",
       "3157                  0.666667               0.333333   \n",
       "\n",
       "      answer_type_reason_explanation  answer_well_written  \n",
       "187                         0.666667             0.888889  \n",
       "1509                        0.000000             0.888889  \n",
       "1954                        0.666667             0.888889  \n",
       "370                         0.500000             1.000000  \n",
       "5945                        0.666667             0.888889  \n",
       "...                              ...                  ...  \n",
       "932                         0.000000             0.833333  \n",
       "4561                        1.000000             0.888889  \n",
       "4706                        1.000000             1.000000  \n",
       "5791                        0.333333             0.888889  \n",
       "3157                        0.666667             1.000000  \n",
       "\n",
       "[912 rows x 30 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6809210526315789"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cut= y_test.apply(lambda x: pd.cut(x,\n",
    "                        [-0.1, .25, .5, .75, 1.1],\n",
    "                        labels=['low', 'medium-', 'medium+', 'high']))\n",
    "\n",
    "y_pred_cut= pd.DataFrame(y_pred).apply(lambda x: pd.cut(x,\n",
    "                        [-0.1, .25, .5, .75, 1.1],\n",
    "                        labels=['low', 'medium-', 'medium+', 'high']))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "scores=[]\n",
    "for col in range(len(y_test.columns)):\n",
    "    scores.append(accuracy_score(y_test_cut.iloc[:,col], y_pred_cut.iloc[:,col]))\n",
    "    \n",
    "mean_scores = np.mean(scores)\n",
    "mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6827850877192982"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
